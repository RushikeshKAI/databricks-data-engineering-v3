# databricks-data-engineering-v3
This course prepares data professionals to leverage the Databricks Lakehouse Platform to productionalize ETL pipelines. You will use Delta Live Tables to define and schedule pipelines that incrementally process new data from a variety of data sources into the Lakehouse. You will also orchestrate tasks with Databricks Workflows and promote code with Databricks Repos.


**Learning objectives**

Use the Databricks Data Science and Engineering Workspace to perform common code development tasks in a data engineering workflow.
Use Spark SQL or PySpark to extract data from a variety of sources, apply common cleaning transformations, and manipulate complex data with advanced functions.
Define and schedule data pipelines that incrementally ingest and process data through multiple tables in the lakehouse using Delta Live Tables in Spark SQL or Python.
Orchestrate data pipelines with Databricks Workflow Jobs and schedule dashboard updates to keep analytics up-to-date.
Configure permissions in Unity Catalog to ensure that users have proper access to databases for analytics and dashboarding. 


